---

#### fact, filters, and dependancies
- name: Set controller nodes facts
  set_fact:
    k8s_controller_nodes: "{{ ansible_play_hosts_all | map('extract', hostvars) | selectattr('k8s_role', 'eq', 'controller') | map(attribute='inventory_hostname') | list }}"

- name: Set computer node facts
  set_fact:
    k8s_compute_nodes: "{{ ansible_play_hosts_all | map('extract', hostvars) | selectattr('k8s_role', 'eq', 'compute') | map(attribute='inventory_hostname') | list }}"

- name: Determine the IP address for the target interface
  ansible.builtin.set_fact:
    ipaddr: >-
      {{ hostvars[inventory_hostname]['ansible_' + (listen_nic | replace('-', '_'))]['ipv4']['address'] }}

- name: Check if the admin file exists
  become: yes
  ansible.builtin.stat:
    path: /etc/kubernetes/admin.conf
  register: file_stat


#### if a controller node has been synced with bootstrap facts, then join it to the cluster
- name: Run join controllers to cluster
  become: yes
  ansible.builtin.shell: |
    kubeadm join {{ lb_vip | default(lb_vip) }}:443 \
      --control-plane \
      --apiserver-advertise-address {{ ipaddr }} \
      --apiserver-bind-port 443 \
      --token {{ join_token }} \
      --discovery-token-ca-cert-hash sha256:{{ cert_hash }} \
      --certificate-key {{ cert_key }}
  args:
    executable: /bin/bash
  when:
    - inventory_hostname in k8s_controller_nodes
    - not file_stat.stat.exists
    - join_token is defined
    - cert_hash is defined
    - cert_key is defined


#### if a compute node has been synced with bootstrap facts, then join it to the cluster 
- name: Run join compute to cluster
  become: yes
  ansible.builtin.shell: |
    kubeadm join {{ lb_vip | default(lb_vip) }}:443 \
      --token {{ join_token }}\
      --discovery-token-ca-cert-hash sha256:{{ cert_hash }}
  args:
    executable: /bin/bash
  when:
    - inventory_hostname in k8s_compute_nodes
    - join_token is defined
    - cert_hash is defined
    - cert_key is defined


#### if a controller has not been bootstrapped and cached, then configure the node as a bootstrap node
- name: Run kubeadm init if and only if bootstrap facts not present
  become: yes
  ansible.builtin.shell: |
    kubeadm init \
      --pod-network-cidr={{ pod_cidr | default(pod_cidr) }} \
      --apiserver-advertise-address={{ ipaddr }} \
      --apiserver-bind-port 443 \
      --control-plane-endpoint={{ lb_vip | default(lb_vip) }} \
      --token {{ k8s_admin_token | default(k8s_admin_token) }} \
      --upload-certs | tee /var/log/kubeadm.log
  args:
    executable: /bin/bash
  when:
    - inventory_hostname in k8s_controller_nodes
    - not file_stat.stat.exists
    - join_token is not defined
    - cert_hash is not defined
    - cert_key is not defined


#### set node ip
- name: Render kubeadm-flags.env template
  become: yes
  template:
    src: kubelet/kubeadm-flags.env.j2
    dest: /var/lib/kubelet/kubeadm-flags.env
    owner: root
    group: root
    mode: '0644'
  notify: Restart kubelet

- name: Flush handlers
  meta: flush_handlers


#### set root kubectl admin privledges on controllers
- name: Add KUBECONFIG to root's bashrc
  become: yes
  ansible.builtin.lineinfile:
    path: /root/.bashrc
    line: 'export KUBECONFIG=/etc/kubernetes/admin.conf'
    state: present
    backup: yes
  when: inventory_hostname in k8s_controller_nodes


#### install plugins
- name: Ensure /opt/k8s_deploy/plugins directory exists with correct permissions
  become: yes
  ansible.builtin.file:
    path: /opt/k8s_deploy/plugins
    state: directory
    owner: root
    group: root
    mode: '0755'
  when:
    - inventory_hostname in k8s_controller_nodes
    - join_token is not defined
    - cert_hash is not defined
    - cert_key is not defined

- name: Render all plugin template files to /opt/k8s_deploy/plugins
  become: yes
  ansible.builtin.template:
    src: "{{ item }}"
    dest: "/opt/k8s_deploy/plugins/{{ item | basename | regex_replace('\\.j2$', '') }}"
    owner: root
    group: root
    mode: '0644'
  with_fileglob:
    - "{{ role_path }}/templates/plugins/*.j2"
  loop_control:
    label: "{{ item | basename }}"
  when:
    - inventory_hostname in k8s_controller_nodes
    - join_token is not defined
    - cert_hash is not defined
    - cert_key is not defined

- name: Apply all YAML files in /opt/k8s_deploy/plugins using kubectl
  become: yes
  ansible.builtin.shell: |
    for file in /opt/k8s_deploy/plugins/*; do
      if [[ -f "$file" ]]; then
        KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f "$file"
        sleep 10
      fi
    done
  args:
    executable: /bin/bash
  when:
    - inventory_hostname in k8s_controller_nodes
    - join_token is not defined
    - cert_hash is not defined
    - cert_key is not defined


#### if a bootstrap node is now configured, set the join details to facts
- name: Set and cache join_token fact
  become: yes
  ansible.builtin.shell: kubeadm token list | grep authentication | awk '{print $1;}'
  register: join_token_output
  changed_when: false
  when: join_token is not defined

- name: Cache join_token
  ansible.builtin.set_fact:
    join_token: "{{ join_token_output.stdout }}"
    cacheable: yes
  when: join_token is not defined

- name: Set and cache cert_hash fact
  become: yes
  ansible.builtin.shell: openssl x509 -in /etc/kubernetes/pki/ca.crt -noout -pubkey | openssl rsa -pubin -outform DER 2>/dev/null | sha256sum | cut -d' ' -f1
  register: cert_hash_output
  changed_when: false
  when: cert_hash is not defined

- name: Cache cert_hash
  ansible.builtin.set_fact:
    cert_hash: "{{ cert_hash_output.stdout }}"
    cacheable: yes
  when: cert_hash is not defined

- name: Set and cache cert_key fact
  become: yes
  ansible.builtin.shell: grep 'certificate-key' /var/log/kubeadm.log | head -n1 | awk '{print $3}'
  register: cert_key_output
  changed_when: false
  when: cert_key is not defined

- name: Cache cert_key
  ansible.builtin.set_fact:
    cert_key: "{{ cert_key_output.stdout }}"
    cacheable: yes
  when: cert_key is not defined


#### restart kubelet
- name: Restart kubelet
  become: yes
  ansible.builtin.systemd:
    name: kubelet
    state: restarted

...
